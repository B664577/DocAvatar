#!/usr/bin/env python3
"""
å¯åŠ¨è„šæœ¬ï¼šç¡®ä¿ DotsOCR æ’ä»¶åœ¨ vLLM æœåŠ¡å™¨å¯åŠ¨å‰è¢«æ­£ç¡®åŠ è½½
"""
import os
import sys
import subprocess

def main():
    # ç¡®ä¿æ’ä»¶è¢«å¯¼å…¥
    try:
        import dots_ocr_plugin
        print("âœ… DotsOCR æ’ä»¶åŠ è½½æˆåŠŸ")
        
        # éªŒè¯æ¨¡å‹æ³¨å†Œ
        from vllm.model_executor.models import ModelRegistry
        supported_archs = ModelRegistry.get_supported_archs()
        if 'DotsOCR' in supported_archs:
            print("âœ… DotsOCR æ¨¡å‹å·²æˆåŠŸæ³¨å†Œåˆ° vLLM")
        else:
            print("âŒ DotsOCR æ¨¡å‹æœªåœ¨ vLLM ä¸­æ³¨å†Œ")
            return 1
            
    except ImportError as e:
        print(f"âŒ æ’ä»¶å¯¼å…¥å¤±è´¥: {e}")
        return 1
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    env = os.environ.copy()
    env['PYTHONPATH'] = f"{os.getcwd()}/dots_ocr_plugin:{env.get('PYTHONPATH', '')}"
    
    # æ„å»º vLLM å‘½ä»¤ - ä½¿ç”¨ç®€å•ç¨³å®šçš„å‚æ•°
    vllm_cmd = [
        'python', './vllm_with_plugin.py', 'serve', 
        './dotsocr/weights/DotsOCR/',
        '--tensor-parallel-size', '1',
        '--gpu-memory-utilization', '0.60',  # ä½¿ç”¨60%GPUå†…å­˜
        '--max-model-len', '4096',           # è¿›ä¸€æ­¥é™ä½
        '--served-model-name', 'model',
        '--trust-remote-code'
    ]
    
    print(f"ğŸš€ å¯åŠ¨ vLLM æœåŠ¡å™¨...")
    print(f"å‘½ä»¤: {' '.join(vllm_cmd)}")
    
    # å¯åŠ¨ vLLM æœåŠ¡å™¨
    try:
        subprocess.run(vllm_cmd, env=env, check=True)
    except subprocess.CalledProcessError as e:
        print(f"âŒ vLLM æœåŠ¡å™¨å¯åŠ¨å¤±è´¥: {e}")
        return 1
    except KeyboardInterrupt:
        print("ğŸ›‘ ç”¨æˆ·ä¸­æ–­")
        return 0
    
    return 0

if __name__ == "__main__":
    sys.exit(main())